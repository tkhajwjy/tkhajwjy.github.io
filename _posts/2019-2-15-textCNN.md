---
layout:     post
title:      textCNN文本分类论文解读
date:       2019-2-15
author:     WJY
header-img: img/01.jpg
catalog: true
tags:

- nlp

---
## textCNN文本分类的应用



![](https://ws1.sinaimg.cn/large/006tKfTcly1g0ppgqbvsmj316o0hm77u.jpg)

## 输入层：

这里的输入有两个通道，其实我们可以看成是一个，因为这两个通道一个是static另一个是non-static。

- static：词向量是预训练好的，在训练中不会变化。

- non-static：词向量随着模型训练而变化，这样的好处是词向量可以根据数据集做适当调整，当数据集比较小的时候，容易过拟合。

输入层是将一个句子所有单词的词向量进行拼接成一个矩阵，每一行代表一个词的词向量，每个句子固定20个词，如果不够的补padding。

## 卷积层：

每个卷积核的大小为`filter_size*embedding_size`，filter_size相当于n-gram中的n的大小，一般为[3,4,5],表示相邻几个词之间有词序关系。embedding_size表示词向量大小。每个filter计算完成之后得到一个列向量，表示该filter从句子中提取的特征，有多少卷积核就能提取多少种特征，上图有4个filter

注意和图像上不同，filter只在纵向移动。

## 池化层

pooling操作就是将卷积得到的向量的最大值提取出来，这样pooling操作之后我们得到一个num_filter维的行向量，即将每个卷积核的最大值连接起来。这样做还有一个好处是，如果之前我们没有对句子进行padding，那么句子长短是不同的，卷积后得到列向量维度也是不同的，可以通过pooling来消除句子之间长度不同的差异。

## 全连接层

为了将pooling层输出的向量转化为我们想要的预测结果，加上一个softmax层。可以使用dropout和L2正则化方式防止过拟合。





